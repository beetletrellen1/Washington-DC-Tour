{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic start to the process.  Finding reviews of people so that tour guides can quickly find if they are mentioned.\n",
    "url = 'https://www.tripadvisor.com/Attraction_Products-g28970-oa0-Washington_DC_District_of_Columbia.html'\n",
    "res = requests.get(url)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to scrape all the different tour companies.\n",
    "def tour_scrape(url):\n",
    "    try:\n",
    "        res = requests.get(url)\n",
    "    except:\n",
    "        print('Bad URL')\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    group = soup.find('div', {'id': 'ATTRACTION_PRODUCTS_LIST'})\n",
    "\n",
    "    # created an open list to put our data into\n",
    "    tour_groups = []\n",
    "    for location in group.find_all('div'):\n",
    "        try:\n",
    "            tour = {}\n",
    "            # focusing on the group to add to future urls to scrape for websites.\n",
    "            tour['group']     = location.find('div').find('div').find('div').find('div').find('div').text\n",
    "            # the website id# is in here. Cannot scrape specific number I need so grabbing the entire row.\n",
    "            # using regex later to get the number I need. \n",
    "            tour['website']   = location.find('a').attrs['onclick']\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        tour_groups.append(tour)\n",
    "#         tour_sites = pd.DataFrame(tour_groups).dropna()\n",
    "#     tour_sites['coder'] = tour_sites['website'].apply(lambda x: re.findall('d\\d+', x))\n",
    "#     tour_sites['coder'] = tour_sites['coder'].apply(lambda x: x if not isinstance(x, list) else x[0] if len(x) else '')\n",
    "    return tour_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list to put all the sites together.  There is approximately 8 different groups\n",
    "sites = []\n",
    "# probably not the best way to start, but putting it at -30 so the first number in the list is 0\n",
    "num = -30\n",
    "for i in range(8):\n",
    "    # the number is based on 30 per page. Then next page is 30 more.\n",
    "    num += 30\n",
    "    url = 'https://www.tripadvisor.com/Attraction_Products-g28970-oa' + str(num) + '-Washington_DC_District_of_Columbia.html'\n",
    "    sites.extend(tour_scrape(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe to easily view the information.\n",
    "df = pd.DataFrame(sites).dropna()\n",
    "# regex to pull the d####### from the website code.\n",
    "df['coder'] = df['website'].apply(lambda x: re.findall('d\\d+', x))\n",
    "# it comes out as a list for some reason. We don't want a list so we use this.\n",
    "df['coder'] = df['coder'].apply(lambda x: x if not isinstance(x, list) else x[0] if len(x) else '')\n",
    "\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('All_tour_dc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapes through the review page\n",
    "def review_scrape(url):\n",
    "    try:\n",
    "        res = requests.get(site_url)\n",
    "    except:\n",
    "        print('Bad URL')\n",
    "\n",
    "    site_soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    group_soup = soup.find('div', {'class': 'listContainer'})\n",
    "\n",
    "    reviews = []\n",
    "    for review in group_soup.find_all('div', {'class': 'review-container'}):\n",
    "        review_dict = {}\n",
    "        try:\n",
    "            # We need to try because some areas have different classes after the review is a week + old.\n",
    "            # Header so the person can easily identify the review.\n",
    "            review_dict['header']       = review.find('div', {'class': 'quote isNew'}).text\n",
    "            # Text so that the person can easily show the reviews information\n",
    "            review_dict['text']         = review.find('p').text\n",
    "            # The day_reviewed helps the person cross validate the passenger experience.\n",
    "            review_dict['day_reviewed'] = review.find('span', {'class': 'ratingDate relativeDate'}).attrs['title']\n",
    "        except:\n",
    "            # these are for the reviews that are a week or older.\n",
    "            try:\n",
    "                review_dict['header']       = review.find('div', {'class': 'quote'}).text\n",
    "                review_dict['text']         = review.find('p').text\n",
    "                review_dict['day_reviewed'] = review.find('span', {'class': 'ratingDate relativeDate'}).attrs['title']\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        reviews.append(review_dict)\n",
    "#     review_data = pd.DataFrame(reviews)\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reviews' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-470bec042f77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'reviews' is not defined"
     ]
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(1):\n",
    "    temp_url = str('https://www.tripadvisor.com/AttractionProductReview-g28970-' + df['coder'] + df['group'] + '-Washington_DC_District_of_Columbia.html')\n",
    "\n",
    "    reviewers = []\n",
    "    numb = -5\n",
    "    try:\n",
    "        for i in range(30):\n",
    "            numb += 5\n",
    "            site_url = str('https://www.tripadvisor.com/AttractionProductReview-g28970-' + df['coder'] + '-or' + str(numb) + df['group'] + '-Washington_DC_District_of_Columbia.html')\n",
    "#             reviewers.extend(review_scrape(site_url))\n",
    "            werf = site_url\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0       https://www.tripadvisor.com/AttractionProductR...\\n18      https://www.tripadvisor.com/AttractionProductR...\\n35      https://www.tripadvisor.com/AttractionProductR...\\n52      https://www.tripadvisor.com/AttractionProductR...\\n69      https://www.tripadvisor.com/AttractionProductR...\\n87      https://www.tripadvisor.com/AttractionProductR...\\n105     https://www.tripadvisor.com/AttractionProductR...\\n123     https://www.tripadvisor.com/AttractionProductR...\\n144     https://www.tripadvisor.com/AttractionProductR...\\n162     https://www.tripadvisor.com/AttractionProductR...\\n179     https://www.tripadvisor.com/AttractionProductR...\\n197     https://www.tripadvisor.com/AttractionProductR...\\n215     https://www.tripadvisor.com/AttractionProductR...\\n233     https://www.tripadvisor.com/AttractionProductR...\\n251     https://www.tripadvisor.com/AttractionProductR...\\n272     https://www.tripadvisor.com/AttractionProductR...\\n290     https://www.tripadvisor.com/AttractionProductR...\\n308     https://www.tripadvisor.com/AttractionProductR...\\n326     https://www.tripadvisor.com/AttractionProductR...\\n344     https://www.tripadvisor.com/AttractionProductR...\\n362     https://www.tripadvisor.com/AttractionProductR...\\n379     https://www.tripadvisor.com/AttractionProductR...\\n397     https://www.tripadvisor.com/AttractionProductR...\\n415     https://www.tripadvisor.com/AttractionProductR...\\n433     https://www.tripadvisor.com/AttractionProductR...\\n451     https://www.tripadvisor.com/AttractionProductR...\\n469     https://www.tripadvisor.com/AttractionProductR...\\n487     https://www.tripadvisor.com/AttractionProductR...\\n505     https://www.tripadvisor.com/AttractionProductR...\\n523     https://www.tripadvisor.com/AttractionProductR...\\n                              ...                        \\n3789    https://www.tripadvisor.com/AttractionProductR...\\n3807    https://www.tripadvisor.com/AttractionProductR...\\n3825    https://www.tripadvisor.com/AttractionProductR...\\n3843    https://www.tripadvisor.com/AttractionProductR...\\n3861    https://www.tripadvisor.com/AttractionProductR...\\n3881    https://www.tripadvisor.com/AttractionProductR...\\n3899    https://www.tripadvisor.com/AttractionProductR...\\n3917    https://www.tripadvisor.com/AttractionProductR...\\n3935    https://www.tripadvisor.com/AttractionProductR...\\n3953    https://www.tripadvisor.com/AttractionProductR...\\n3971    https://www.tripadvisor.com/AttractionProductR...\\n3989    https://www.tripadvisor.com/AttractionProductR...\\n4007    https://www.tripadvisor.com/AttractionProductR...\\n4025    https://www.tripadvisor.com/AttractionProductR...\\n4043    https://www.tripadvisor.com/AttractionProductR...\\n4061    https://www.tripadvisor.com/AttractionProductR...\\n4079    https://www.tripadvisor.com/AttractionProductR...\\n4097    https://www.tripadvisor.com/AttractionProductR...\\n4115    https://www.tripadvisor.com/AttractionProductR...\\n4133    https://www.tripadvisor.com/AttractionProductR...\\n4151    https://www.tripadvisor.com/AttractionProductR...\\n4169    https://www.tripadvisor.com/AttractionProductR...\\n4187    https://www.tripadvisor.com/AttractionProductR...\\n4204    https://www.tripadvisor.com/AttractionProductR...\\n4221    https://www.tripadvisor.com/AttractionProductR...\\n4239    https://www.tripadvisor.com/AttractionProductR...\\n4257    https://www.tripadvisor.com/AttractionProductR...\\n4275    https://www.tripadvisor.com/AttractionProductR...\\n4293    https://www.tripadvisor.com/AttractionProductR...\\n4310    https://www.tripadvisor.com/AttractionProductR...\\nLength: 240, dtype: object'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
